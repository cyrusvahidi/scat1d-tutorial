{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kymatio Workshop 2022: Scattering1D Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Time Scattering in Kymatio"
      ],
      "metadata": {
        "id": "hQA3GiNcYqgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will work through examples of `Scattering1D` (Time Scattering) in Kymatio.\n",
        "\n",
        "The intention is to gain an intuition of the physical properties of modulated signals and their scattering transform.\n",
        "\n",
        "### Part I\n",
        "* understanding the scattering filterbank construction parameters (`J`, `Q`, `averaging`, `order`, `paths`)\n",
        "* plotting the wavelet filterbank\n",
        "* visualizing the response to modulated sounds that appear in music and speech\n",
        "    - amplitude modulation (tremolo)\n",
        "    - frequency modulation (vibrato)\n",
        "    - attacks (note onset)\n",
        "    - amplitude modulation interference \n",
        "    - musical instrument playing techniques\n",
        "\n",
        "### Part II\n",
        "* Generate a dataset of synthetic signals with varying spectral shape and interference patterns\n",
        "* Unsupervised manifold embedding of the nearest neighbour graph (Isomap) of the dataset under Scattering1D\n",
        "\n",
        "Further documentation can be found here: [Kymatio Github](https://github.com/kymatio/kymatio)"
      ],
      "metadata": {
        "id": "MMMaI0WwY0pE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $ U_1 x [\\lambda, t] = |x * \\psi_{\\lambda}|(t) $\n",
        "- $ S_1 x [\\lambda, t] = (U_1 x * \\phi_t)(\\lambda, t) $\n",
        "- $ S_2 x [\\lambda, \\lambda_2, t] = (|U_1 x * \\psi_{\\lambda_2}| * \\phi_T)(\\lambda, t) $"
      ],
      "metadata": {
        "id": "jHOiRPJufYvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n",
        "Let's install the dev branch of Kymatio and its dependencies"
      ],
      "metadata": {
        "id": "MXCUKjJ0bEak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z38BZZTYolQ",
        "outputId": "1ac1fd96-798c-4a22-db59-0c0ecfcb2a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kymatio in /usr/local/lib/python3.7/dist-packages (0.3.dev0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.21.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.4)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from kymatio) (5.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kymatio) (21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kymatio) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install kymatio\n",
        "# !pip install git+https://github.com/kymatio/kymatio.git@dev "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import \n",
        "- Let's import the torch frontend\n",
        "- The frontend takes few parameters and handles filterbank construction and organisation of the coefficients\n",
        "- Several frontends are available, including NumPy and Tensorflow"
      ],
      "metadata": {
        "id": "4maN1MuzbOsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, torch, librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "import scipy\n",
        "\n",
        "from kymatio.torch import Scattering1D\n",
        "from kymatio.scattering1d.filter_bank import scattering_filter_factory\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Qry3T3vJbPUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate a Scattering Filterbank"
      ],
      "metadata": {
        "id": "2IukvoLHcLC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will use a core function `scattering_filter_factory` to inspect the construction of a scattering filterbank. This step is usually handled by the frontend.\n",
        "\n",
        "To construct the filterbank, we must define the following parameters: \n",
        "* $N$: the temporal support of the filters \n",
        "  - this corresponds to the size of the input signal and must be a power of two\n",
        "* $J$: the maximum scale \n",
        "  - The lowest scale (largest filter, lowest central frequency) will be defined over a time support of $2^J$. $J$ also determines the total number of octaves.\n",
        "* $Q$: the number of wavelets filter per octave in the first-order filterbank \n",
        "  - $Q$ determines how well we can localize a signal in frequency. When $Q = 1$, we get a dyadic wavelet filterbank i.e. subsequent wavelet filter central frequencies are spaced by a factor two and there is exactly one filter per octave. Smaller values of $Q$ result in filters that are wider in the frequency domain and narrower in the time domain. The choice of $Q$ depends on the application. Typically for audio, higher values of $Q$ (between 4 and 16) enable better frequency localization of highly oscillatory signals.\n",
        "* $T$: the temporal support of the lowpass filter\n",
        "  - this controls the amount of imposed invariance to time-shifts. Set to $2^J$ by default."
      ],
      "metadata": {
        "id": "oVx1rr9YcYVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the filters by calling `scattering_filter_factory`. It returns the lowpass filter (phi_f), the first-order wavelet filters (psi1_f), and the second-order filters (psi2_f)."
      ],
      "metadata": {
        "id": "P2mkV4h0dL9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 4096\n",
        "J = 8\n",
        "Q = 8 \n",
        "\n",
        "phi_f, psi1_f, psi2_f, _ = scattering_filter_factory(np.log2(N), J, Q, T=2**J)"
      ],
      "metadata": {
        "id": "RmjCSUSocL9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`phi_f` is a dictionary that contains the low-pass filter at different resolutions at each integer key. For example, `phi_f[0]` is at resolution `T` while `phi_f[1]` is at resolution `T / 2`.\n",
        "\n",
        "`psi1_f` (order 1) and `psi2_f` (order 2) are lists of dictionaries that contain the specification of each wavelet bandpass filter. \n",
        "\n",
        "Each dictionary contains: \n",
        "- the filter `0`\n",
        "- the filter's normalized centre frequency `xi` \n",
        "- the filter's width `sigma`\n",
        "- the filter's scale `j`"
      ],
      "metadata": {
        "id": "inThJDMedhHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''temporal support of the lowpass filter at each resolution'''\n",
        "print([len(phi) for k, phi in phi_f.items() if type(k) is int])\n",
        "\n",
        "'''A first order filter'''\n",
        "print(f'filter 0: {psi1_f[0][0]}')\n",
        "\n",
        "'''A first order filter's scale'''\n",
        "print(f'filter 0 scale: {psi1_f[0][\"j\"]}')\n",
        "\n",
        "'''A first order filter's central frequency'''\n",
        "print(f'filter 0 centre frequency: {psi1_f[0][\"xi\"]}')\n",
        "\n",
        "'''A first order filter's central frequency in Hz, assuming a sampling rate of 4096 Hz'''\n",
        "print(f'filter 0 centre frequency (Hz) {psi1_f[0][\"xi\"] * 4096}')\n",
        "\n",
        "'''A first order filter's characteristic width'''\n",
        "print(f'filter 0 width: {psi1_f[0][\"sigma\"]}')"
      ],
      "metadata": {
        "id": "V0YwkfPncUCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the filters\n",
        "\n",
        "We can now plot the first-order filters. \n",
        "\n",
        "First, we plot display the lowpass filter (at full resolution) in red. We then plot each of the bandpass filters in blue (in the fourier domain). Since we don’t care about the negative frequencies, we limit the plot to the frequency interval [0, 0.5] (nyquist).\n",
        "\n",
        "* what properties can you observe from the filters?\n",
        "* how does the bandwidth change with frequency?\n",
        "* how many filters are there?\n",
        "  - how does this change with `J` and `Q`?\n",
        "* what's the ratio between the highest and lowest centre frequency?"
      ],
      "metadata": {
        "id": "7HmLQ5TAevs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.figure(figsize=(10, 5))\n",
        "\n",
        "# FIRST-ORDER FILTERBANK\n",
        "_ = plt.plot(np.arange(N) / N, phi_f[0], 'r')\n",
        "\n",
        "for psi_f in psi1_f:\n",
        "    plt.plot(np.arange(N)/N, psi_f[0], 'b')\n",
        "\n",
        "plt.xlim(0, 0.5)\n",
        "\n",
        "plt.xlabel(r'$\\omega$', fontsize=18)\n",
        "plt.ylabel(r'$\\hat\\psi_j(\\omega)$', fontsize=18)\n",
        "_ = plt.title('First-order filters (Q = {})'.format(Q), fontsize=18)"
      ],
      "metadata": {
        "id": "F4lDfOWce4qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.figure(figsize=(10, 5))\n",
        "\n",
        "# SECOND-ORDER FILTERBANK\n",
        "for psi_f in psi2_f:\n",
        "    plt.plot(np.arange(N)/N, psi_f[0], 'b')\n",
        "\n",
        "plt.xlim(0, 0.5)\n",
        "\n",
        "plt.xlabel(r'$\\omega$', fontsize=18)\n",
        "plt.ylabel(r'$\\hat\\psi_j(\\omega)$', fontsize=18)\n",
        "_ = plt.title('Second-order filters (Q = 1)', fontsize=18)"
      ],
      "metadata": {
        "id": "gBrAG1tMDffJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scattering1D frontend \n",
        "\n",
        "- Now we will create the scattering 1D torch frontend object. This constructs the filterbank as we did in the previous section and provides convenient methods to compute the scattering transform (`__call__`) and collect the coefficients at each order (`meta`).\n",
        "- The constructor requires a specification of the maximum scale `J` (number of octaves) and the input signal length `shape`. \n",
        "- We can also specify the number of filters per octave `Q` (default = 1), lowpass temporal support `T` (default = $2^J$), `max_order` (default = 2) and whether to get `U` or `S` with the kwarg `average`"
      ],
      "metadata": {
        "id": "AiwxiUqafUdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kymatio.torch import Scattering1D\n",
        "\n",
        "Fs = 2**14 # sampling rate\n",
        "duration = 2 # signal duration\n",
        "J = 12 # maximum wavelet scattering scale\n",
        "Q = 8\n",
        "\n",
        "scat1d = Scattering1D(J=J, Q=Q, shape=duration * Fs, average=True)"
      ],
      "metadata": {
        "id": "1-X_QrFnfV9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To inspect the output shape, let's compute the scattering transform of a random input. \n",
        "* Computing the scattering transform of a signal is achieved using the __call__ method of the Scattering1D class. \n",
        "* The output is an array of shape (C, T). C is the number of scattering coefficient outputs, and T is the number of samples along the time axis. \n",
        "* This is typically much smaller than the number of input samples since the scattering transform performs temporal averaging\n",
        "\n",
        "- Try changing, the frontend's kwargs. What do you observe?"
      ],
      "metadata": {
        "id": "0CsWOgWTgak1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(scat1d(torch.randn(duration * Fs)).shape)"
      ],
      "metadata": {
        "id": "b0_lfwWsfWUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting first and second order coefficients\n",
        "* `Scattering1D` returns a vector per timestep, concatenating zeroth, first and second order coefficients. \n",
        "* To display the scattering coefficients, we have to identify the indices for each order. \n",
        "* A `Scattering1D` object contains meta information, including the indices of each order"
      ],
      "metadata": {
        "id": "6euQ9iW-hS9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta = scat1d.meta()\n",
        "order0 = np.where(meta['order'] == 0)[0]\n",
        "order1 = np.where(meta['order'] == 1)[0]\n",
        "order2 = np.where(meta['order'] == 2)[0]"
      ],
      "metadata": {
        "id": "e8QLq2xkg0Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the scattering transform of modulated signals\n",
        "- Now we are going to construct an amplitude modulated harmonic signal. \n",
        "  * it's a sinusoidal signal that contains 4 harmonics and sinusoidal amplitude modulation (tremolo)\n",
        "- To facilitate visualization of the resulting properties of the signal, we will use the filterbank's meta\n",
        "- We will set fundamental frequency to correspond to the centre frequency of a first-order wavelet\n",
        "- We will set the modulation frequency to correspond to the centre frequency of a second-order wavelet\n",
        "\n",
        "- try using different combinations of first and second-order frequencies to synthesize the signal\n",
        "  * be careful here, as some second-order paths do not have every first-order as a parent"
      ],
      "metadata": {
        "id": "xsKQkvAeh47n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scattering plot helper functions"
      ],
      "metadata": {
        "id": "UH8cYwJmqtl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_scattering(x, scat1d_u, scat1d, lambda1_idx=None):\n",
        "    \"\"\" Compute U1, S1 and S2\n",
        "\n",
        "        Parameters:\n",
        "            x -- signal\n",
        "            scat1d_u -- Scattering1D instance with average=False\n",
        "            scat1d -- Scattering1D instance\n",
        "            lambda1_idx -- target lambda1 index for S2 visualization\n",
        "\n",
        "        Returns:\n",
        "            u1 -- unaveraged scalogram of x\n",
        "            s1 -- first order scattering transform of x\n",
        "            s2 -- second order scattering transform of x\n",
        "    \"\"\"\n",
        "    ''' compute the unaveraged scattering transform Ux'''\n",
        "    Ux = scat1d_u(x)\n",
        "    ''' get the first-order coefficients '''\n",
        "    Ux = [u for key, u in Ux.items() if len(key) == 1]\n",
        "    max_samples = max([u.shape[-1] for u in Ux]) # largest length unaveraged transform\n",
        "    ''' resample the first order coefficient to same temporal shape'''\n",
        "    Ux = [scipy.signal.resample(u.numpy(), max_samples, axis=-1) for u in Ux]\n",
        "    Ux = torch.tensor(np.concatenate(Ux))\n",
        "\n",
        "    meta = scat1d.meta()\n",
        "    order1 = np.where(meta['order'] == 1)[0]\n",
        "\n",
        "    ''' Select indices of order2 coefficients that corresponds to the \n",
        "        order1 parent lambda1_idx\n",
        "    '''\n",
        "    if lambda1_idx:\n",
        "        # get s2 keys\n",
        "        key = [x for x in meta['key'] if len(x) > 1]\n",
        "\n",
        "        order2 = [x[1] for x in key if x[0] == lambda1_idx]\n",
        "    else: \n",
        "        order2 = np.where(meta['order'] == 2)[0]\n",
        "\n",
        "    '''Compute the scattering transform'''\n",
        "    Sx = scat1d(x)\n",
        "    S1 = Sx[order1]\n",
        "    S2 = Sx[order2]\n",
        "\n",
        "    return Ux, S1, S2\n",
        "  \n",
        "  \n",
        "def plot_scat1d(u1, s1, s2):\n",
        "    \"\"\" Plot u1, s1 and s2\n",
        "\n",
        "      Parameters:\n",
        "          u1 -- unaveraged scalogram\n",
        "          s1 -- first order scattering transform\n",
        "          s2 -- second order scattering transform\n",
        "      Returns:\n",
        "  \"\"\"\n",
        "    plt.figure(figsize=(10, 15))\n",
        "    # plt.tick_params(\n",
        "    #     axis='x',          # changes apply to the x-axis\n",
        "    #     which='both',      # both major and minor ticks are affected\n",
        "    #     bottom=False,      # ticks along the bottom edge are off\n",
        "    #     top=False,         # ticks along the top edge are off\n",
        "    #     left=False,\n",
        "    #     right=False,\n",
        "    #     labelbottom=False)\n",
        "\n",
        "    ''' plot U1, S1, S2 '''\n",
        "    for idx, s in enumerate([u1, s1, s2]):\n",
        "        ax = plt.subplot(3, 1, idx + 1)\n",
        "        plt.imshow(s, aspect='auto', origin='lower', cmap=plt.get_cmap('jet'))\n",
        "        ax.set_xticklabels([]); ax.set_yticklabels([])\n",
        "\n",
        "    plt.subplots_adjust(wspace=0, hspace=0.1)\n",
        "\n",
        "\n",
        "def plot_signals(signals, scat1d_u, scat1d):\n",
        "    u1_concat = []\n",
        "    s1_concat = []\n",
        "    s2_concat = []\n",
        "\n",
        "    def append_silence():\n",
        "        u1_concat.append(torch.zeros(u1.shape[0], u1.shape[1] // 4))\n",
        "        s1_concat.append(torch.zeros(s1.shape[0], s1.shape[1] // 4))\n",
        "        s2_concat.append(torch.zeros(s2.shape[0], s2.shape[1] // 4))\n",
        "\n",
        "    for x in signals:\n",
        "        u1, s1, s2 = compute_scattering(x, scat1d_u, scat1d, lambda1_idx=None)\n",
        "        append_silence()\n",
        "        u1_concat.append(u1)\n",
        "        s1_concat.append(s1)\n",
        "        s2_concat.append(s2)\n",
        "        append_silence()\n",
        "\n",
        "    u1 = np.concatenate(u1_concat, axis=-1)\n",
        "    s1 = np.concatenate(s1_concat, axis=-1)\n",
        "    s2 = np.concatenate(s2_concat, axis=-1)\n",
        "    plot_scat1d(u1, s1, s2)"
      ],
      "metadata": {
        "id": "dIk6sVNkhPE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthesize a harmonic signal with tremolo"
      ],
      "metadata": {
        "id": "uHTSZiX3q0UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f0_xi_idx = 30 # coefficient index for the first order frequency\n",
        "fm_xi_idx = 8 # coefficient index for the second order frequency\n",
        "\n",
        "f0 = meta['xi'][order1[f0_xi_idx], 0] * Fs # get the central frequency of a first order filter\n",
        "fm = meta['xi'][order2[fm_xi_idx], 1] * Fs # get the central frequency of a second order filter\n",
        "print(f'fundamental frequency: {f0} Hz')\n",
        "print(f'modulation frequency: {fm} Hz')\n",
        "\n",
        "''' synthesize a harmonic signal'''\n",
        "num_harmonics = 5\n",
        "harmonics = torch.zeros(num_harmonics, duration * Fs)\n",
        "t = torch.arange(0, duration, float(1/Fs))\n",
        "modulator = torch.sin(2.0 * np.pi * fm * t)\n",
        "harmonics[0] = torch.sin(2.0 * np.pi * f0 * t) * modulator\n",
        "\n",
        "for i in range(1, num_harmonics):\n",
        "    harmonics[i] = torch.cos(2.0 * np.pi * (f0 * i) * t) * modulator\n",
        "    \n",
        "x_am = torch.sum(harmonics, dim=0) # sum the harmonics\n",
        "x_am /= torch.max(torch.abs(x_am)) # normalize the amplitude\n",
        "\n",
        "Audio(x_am, rate=Fs)"
      ],
      "metadata": {
        "id": "8ZaeN4OBh4jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot its fourier spectrogram"
      ],
      "metadata": {
        "id": "atRXQlR6q5TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.figure(figsize=(10, 5))\n",
        "_ = plt.specgram(x_am, Fs=Fs)\n",
        "plt.xlabel(r'$t$ (seconds)', fontsize=18)\n",
        "plt.ylabel(r'$f$ (Hz)', fontsize=18)\n",
        "_ = plt.title('Fourier Spectrogram of the AM harmonic signal', fontsize=18)"
      ],
      "metadata": {
        "id": "1-3_C1jhyrqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The second-order scattering transform is of the form $S_2x[\\lambda, \\lambda_2]$\n",
        "* We want to visualize the response of the second-order wavelet filterbank around a particular first-order parent $\\lambda$\n",
        "* Let's use the $\\lambda$ that corresponds to the fundamental frequency of the synthesized signal\n",
        "* It's important to note that not every possible pairing between $\\lambda$ and $\\lambda_2$ is performed by the scattering transform. For efficiency purposes, a second-order wavelet filter is only applied to first-order bands that are of smaller scale.\n",
        "* We will also visualize $U_1$, to show the effects of averaging on $S_1$"
      ],
      "metadata": {
        "id": "J8ex0Yz9jRox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Scattering of the AM Harmonic Signal"
      ],
      "metadata": {
        "id": "akvwNNV7q-nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unaveraged scattering\n",
        "scat1d_u = Scattering1D(J=J, Q=Q, shape=duration * Fs, average=False, vectorize=False)\n",
        "\n",
        "# scattering\n",
        "scat1d = Scattering1D(J=J, Q=Q, shape=duration * Fs)\n",
        "\n",
        "# plot U_1, S_1, and S_2 coefficients around lambda corresponding to f0\n",
        "u1, s1, s2 = compute_scattering(x_am, scat1d_u, scat1d, lambda1_idx=None)\n",
        "plot_scat1d(u1, s1, s2)"
      ],
      "metadata": {
        "id": "B5DeOohwizEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What differences are there between $U_1$, $S_1$ and $S_2$?\n",
        "* What information is lost? How is it recovered?"
      ],
      "metadata": {
        "id": "nU2xGqsk1QO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interference Patterns\n",
        "- Now we are going to construct a chord of two notes \n",
        "  * each note is a sinusoidal signal that contains 4 harmonics.\n",
        "  * the fundamental frequencies of the notes are $f_0$ and $f_0'$ \n",
        "  * let's pick an $\\xi$ from the filterbank for $f_0$, and one half step above it $\\xi+\\xi/12$ as $f_0'$.\n"
      ],
      "metadata": {
        "id": "pricTSw0rUIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f0_idx = 30 # coefficient index for the first note in the chord\n",
        "df_xi_idx = 8\n",
        "\n",
        "f0 = meta['xi'][order1[f0_idx], 0] * Fs # get the central frequency of a first order filter\n",
        "df = f0 / 12 \n",
        "f0_2 = f0 + 2 * df\n",
        "\n",
        "print(f'first note fundamental frequency: {f0} Hz')\n",
        "print(f'second note fundamental frequency: {f0_2} Hz')\n",
        "\n",
        "x_chord = 0\n",
        "for f in [f0, f0_2]:\n",
        "    num_harmonics = 4\n",
        "    t = torch.arange(0, duration, 1/Fs)\n",
        "    harmonics = torch.zeros(num_harmonics, duration * Fs)\n",
        "    harmonics[0] = torch.sin(2.0 * np.pi * f * t) \n",
        "    for i in range(1, num_harmonics):\n",
        "        harmonics[i] = torch.sin(2.0 * np.pi * (f * 2 ** i) * t) #four harmonics\n",
        "\n",
        "    x = torch.sum(harmonics, dim=0) # sum the harmonics\n",
        "    x_chord += x\n",
        "x_chord /= torch.max(torch.abs(x_chord)) # normalize the amplitude\n",
        "Audio(x_chord, rate=Fs)"
      ],
      "metadata": {
        "id": "73LuQKDdknDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Same two notes, arranged in arpeggio instead of a single chord"
      ],
      "metadata": {
        "id": "oaB9W0KE8bSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_arp = []\n",
        "for f in [f0, f0_2]:\n",
        "    num_harmonics = 4\n",
        "    t = torch.arange(0, duration, 1/Fs)\n",
        "    harmonics = torch.zeros(num_harmonics, duration//2 * Fs)\n",
        "    harmonics[0] = torch.sin(2.0 * np.pi * f * t[:len(t)//2]) \n",
        "    for i in range(1, num_harmonics):\n",
        "        harmonics[i] = torch.sin(2.0 * np.pi * (f * 2 ** i) * t[:len(t)//2]) #four harmonics\n",
        "\n",
        "    x = torch.sum(harmonics, dim=0) # sum the harmonics\n",
        "    x_arp.extend(x)\n",
        "x_arp = torch.tensor(x_arp)\n",
        "x_arp /= torch.max(torch.abs(x_arp)) # normalize the amplitude\n",
        "Audio(x_arp,rate=Fs)"
      ],
      "metadata": {
        "id": "ttS1DOXM8aFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scat1d = Scattering1D(J=8, Q=12, shape=duration * Fs, average=True)\n",
        "scat1d_u = Scattering1D(J=8, Q=12, shape=duration * Fs, average=False, vectorize=False)\n",
        "\n",
        "plot_signals([x_chord, x_arp], scat1d_u, scat1d)"
      ],
      "metadata": {
        "id": "xKNR1PAc29FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compare the $U_1$, $S_1$, $S_2$ of the chord and arpeggio signals, when are they more distinguishable and when are they not?"
      ],
      "metadata": {
        "id": "PLW-j3Q5tSmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequency modulated sounds\n",
        "- We are constructing a harmonic sinusoidal signal with frequency modulation\n",
        "  * the carrier frequency is f0\n",
        "  * the modulation frequency is fm, chosen to be the same as the amplitude modulation frequency earlier\n",
        "  * the depth of frequency modulation is adjustable"
      ],
      "metadata": {
        "id": "IAhsn8Hb4EgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f0_idx = 30\n",
        "f0 = meta['xi'][order1[f0_idx], 0] * Fs \n",
        "fm = meta['xi'][order2[8], 1] * Fs \n",
        "depth = 30\n",
        "print(f'fundamental frequency: {f0} Hz')\n",
        "print(f'modulation frequency: {fm} Hz')\n",
        "print(f'depth of modulaion: {depth}')\n",
        "\n",
        "num_harmonics = 5\n",
        "harmonics = torch.zeros(num_harmonics, duration * Fs)\n",
        "t = torch.arange(0, duration, 1/Fs)\n",
        "\n",
        "\n",
        "modulator = torch.sin(2.0 * np.pi * fm * t)\n",
        "harmonics[0] = torch.sin(2.0 * np.pi * f0 * t + depth * modulator)\n",
        "\n",
        "for i in range(1, num_harmonics):\n",
        "    harmonics[i] = torch.sin(2.0 * np.pi * (f0 * i) * t + depth * modulator) #four harmonics with amplitude modulator\n",
        "    \n",
        "x_vibrato = torch.sum(harmonics, dim=0) # sum the harmonics\n",
        "x_vibrato /= torch.max(torch.abs(x_vibrato)) # normalize the amplitude\n",
        "Audio(x_vibrato, rate=Fs)"
      ],
      "metadata": {
        "id": "DDpXzdSx-LLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scat1d = Scattering1D(J=J, Q=12, shape=duration * Fs, average=True)\n",
        "scat1d_u = Scattering1D(J=J, Q=12, shape=duration * Fs, average=False, vectorize=False)\n",
        "\n",
        "plot_signals([x_am, x_vibrato], scat1d_u, scat1d)"
      ],
      "metadata": {
        "id": "rs3aanJQWY5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Try adjusting Q, how does it affect difference between the $S_2$ coefficients?"
      ],
      "metadata": {
        "id": "0kuYoNjPg3Si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Noisy attack"
      ],
      "metadata": {
        "id": "SdgL0oTO93Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decay_r = -6\n",
        "x_attack = (torch.rand(len(t))*2-1) * torch.exp(i*decay_r*t)\n",
        "x_attack /= torch.max(torch.abs(x_attack))\n",
        "Audio(x_attack,rate=Fs)"
      ],
      "metadata": {
        "id": "h4b49iFb9f9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot U_1, S_1, and S_2 coefficients around lambda corresponding to f0\n",
        "u1, s1, s2 = compute_scattering(x_attack, scat1d_u, scat1d, lambda1_idx=None)\n",
        "plot_scat1d(u1, s1, s2)"
      ],
      "metadata": {
        "id": "1ZJHp_b-WhWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "putting them all together and plot"
      ],
      "metadata": {
        "id": "QZY3sgxr5iFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scat1d = Scattering1D(J=J, Q=12, shape=duration * Fs, average=True)\n",
        "scat1d_u = Scattering1D(J=J, Q=12, shape=duration * Fs, average=False, vectorize=False)\n",
        "plot_signals([x_am,x_chord,x_arp,x_attack,x_vibrato], scat1d_u, scat1d)"
      ],
      "metadata": {
        "id": "cI6FglRCjiqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II: One or Two Frequencies? The scattering transform answers.\n",
        "\n",
        "* This part of the tutorial will explore similarity retrieval of harmonic sounds with the scattering transform\n",
        "* Scattering transforms can detect interference patterns in the time-frequency domain ..."
      ],
      "metadata": {
        "id": "j4HWkHXZqh-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import scipy.signal\n",
        "from matplotlib import pyplot as plt\n",
        "import tqdm\n",
        "from sklearn.manifold import Isomap\n",
        "import kymatio"
      ],
      "metadata": {
        "id": "RIJu1jI8Fyuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function build one sample of complex tones according to the following additive synthesis model: \n",
        "\n",
        "\n",
        "$  \\boldsymbol{y}_{\\alpha,r}(t) =\n",
        "    \\sum_{n=1}^{N}\n",
        "    \\dfrac{\n",
        "    1 + (-1)^{n} r\n",
        "    }{\n",
        "    n^{\\alpha}\n",
        "    }\n",
        "    \\cos(n f_0 t)\n",
        "    \\boldsymbol{\\phi}_T(t)\n",
        "$\n",
        "\n"
      ],
      "metadata": {
        "id": "FYHQ_hqvFEyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(fourier_decay, odd_to_even, f0=[16], N=2**10):\n",
        "    f0_choice = random.choice(f0)\n",
        "    n_partials = int(N/(2*f0_choice)) - 1\n",
        "    t = np.linspace(0, 1, N, endpoint=False)\n",
        "    partials = np.zeros((n_partials, N))\n",
        "    for partial_id in range(n_partials):\n",
        "        frequency = (1+partial_id) * f0_choice\n",
        "        amplitude = (1+odd_to_even*(-((partial_id)%2)**2))/(1+partial_id)**fourier_decay\n",
        "        partial = amplitude * np.cos(2*np.pi*frequency*t)\n",
        "        partials[partial_id, :] = partial\n",
        "        \n",
        "    x = np.sum(partials, axis=0) * scipy.signal.hann(N)\n",
        "\n",
        "    return (x , f0_choice)"
      ],
      "metadata": {
        "id": "8kgqYEgSFHq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now plot and see the dataset (in time and frequency), with different $\\alpha$ and $r$:"
      ],
      "metadata": {
        "id": "RQITxiXVFXjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2**10\n",
        "f0_list = range(12,24)\n",
        "\n",
        "alphas = np.ravel(np.tile(np.array([0, 0.5, 1.0, 2.5, 2.0]), (1, 5)))\n",
        "rs = np.ravel(np.tile(np.array([0, 0.25, 0.5, 0.75, 1.0]), (5, 1)).T)\n",
        "fig, axs = plt.subplots(5, 5, figsize=(10, 10), sharex=True, sharey=True)\n",
        "axs = axs.flatten()\n",
        "\n",
        "signals = []\n",
        "\n",
        " \n",
        "for i in range(len(alphas)):\n",
        "    a = alphas[i]\n",
        "    r = rs[i]\n",
        "    x, _ = generate(a, r, f0=f0_list, N=N)\n",
        "    x = x/np.max(x)\n",
        "    signals.append(x)\n",
        "    axs[i].plot(0*x, 'k')\n",
        "    axs[i].plot(x)\n",
        "    axs[i].set_xlim(0, N)\n",
        "    axs[i].set_ylim(-1.1, 1.1)\n",
        "    axs[i].set_title(\"α = {:.2f} ; r = {:.2f}\".format(a, r), fontsize=10)\n",
        "    axs[i].set_yticks([])\n",
        "    axs[i].set_xticks([])\n",
        "    axs[i].spines[\"top\"].set_visible(False)\n",
        "    axs[i].spines[\"right\"].set_visible(False)\n",
        "    axs[i].spines[\"bottom\"].set_visible(False)\n",
        "    axs[i].spines[\"left\"].set_visible(False)\n",
        "    axs[i].grid('on', linestyle='--', alpha=0.5)\n",
        " "
      ],
      "metadata": {
        "id": "QGrrBMO5FYb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(5, 5, figsize=(10, 10), sharex=True, sharey=True)\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    x = signals[i]\n",
        "    t = np.linspace(0, 1, N, endpoint=False)\n",
        "    axs[i].plot(np.log2(N*t[1:(1+N//2)]), np.log10(np.abs(np.fft.rfft(x)))[1:])\n",
        "    axs[i].set_ylim(-5, 3)\n",
        "    axs[i].set_title(\"α = {:.2f} ; r = {:.2f}\".format(a, r), fontsize=10)\n",
        "    axs[i].set_xlim(3, 9)\n",
        "    axs[i].set_xticks([])\n",
        "    axs[i].set_yticks([])\n",
        "    axs[i].spines[\"top\"].set_visible(False)\n",
        "    axs[i].spines[\"right\"].set_visible(False)\n",
        "    axs[i].spines[\"bottom\"].set_visible(False)\n",
        "    axs[i].spines[\"left\"].set_visible(False)"
      ],
      "metadata": {
        "id": "kVb4od5lGDzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do $\\alpha$ and $r$ control ?\n",
        "\n",
        "You can alos listen to the synthetic sound, and play with different values of $\\alpha$ and $r$, with a fixed f0. "
      ],
      "metadata": {
        "id": "ikDRQOpCGJ53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ipywidgets import interactive\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "\n",
        "def render(alpha, r):\n",
        "    signal, _ = generate(alpha, r, f0=[256], N=2**15)\n",
        "    rate = 22050\n",
        "    display(Audio(data=signal, rate=rate, autoplay=True))\n",
        "    return signal * 0.5\n",
        "    \n",
        "v = interactive(render, alpha=(0.0, 2.0), r=(0.0, 1.0))\n",
        "display(v)"
      ],
      "metadata": {
        "id": "hc_I70iKGK37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we now geneate the dataset, for all $alpha$s and $r$s chosen, with a varying f0. We refer to this dataset as the complex dataset. "
      ],
      "metadata": {
        "id": "CCVlCCbxGXah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_alpha = 75\n",
        "n_r = 75\n",
        "\n",
        "min_alpha = 0.0\n",
        "max_alpha = 2.0\n",
        "min_r = 0.0\n",
        "max_r = 1.0\n",
        "\n",
        "r_range = np.linspace(min_r, max_r, n_r, endpoint=True)\n",
        "alpha_range = np.linspace(min_alpha, max_alpha, n_alpha, endpoint=True)\n",
        "frequencies = np.zeros((n_r, n_alpha))\n",
        "\n",
        "\n",
        "X = np.zeros((n_r, n_alpha, N))\n",
        "for i, r in tqdm.tqdm(enumerate(r_range), total=len(r_range)):\n",
        "    for j, a in enumerate(alpha_range):\n",
        "        X[i, j, :], frequencies[i, j]  = generate(a, r, f0=f0_list, N=N)"
      ],
      "metadata": {
        "id": "TSjiLJVPGYRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also create a simpler dataset, with a fixed value of f0. We refer to the this dataset as the simple dataset. \n"
      ],
      "metadata": {
        "id": "FXFbDK2EGbkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_alpha = 75\n",
        "n_r = 75\n",
        "\n",
        "min_alpha = 0.0\n",
        "max_alpha = 2.0\n",
        "min_r = 0.0\n",
        "max_r = 1.0\n",
        "\n",
        "r_range = np.linspace(min_r, max_r, n_r, endpoint=True)\n",
        "alpha_range = np.linspace(min_alpha, max_alpha, n_alpha, endpoint=True)\n",
        "\n",
        "X_simple = np.zeros((n_r, n_alpha, N))\n",
        "for i, r in tqdm.tqdm(enumerate(r_range), total=len(r_range)):\n",
        "    for j, a in enumerate(alpha_range):\n",
        "        x, _ = generate(a, r, f0=[16], N=N)\n",
        "        x = x/np.max(x)\n",
        "        X_simple[i, j, :] = x"
      ],
      "metadata": {
        "id": "A-QBYugNGevG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Representations\n",
        "\n",
        "The goal here is to see, depending on the representation of the audio signals, if we can learn an embedding that capture the parameters of our data ($\\alpha$ and $r$). \n",
        "To do so, we will usr the Isomap algorithm ([link](https://www.science.org/doi/pdf/10.1126/science.290.5500.2319?casa_token=3jO92IQhP-oAAAAA:BsWxsyAUddTwP8NUO0GY7YZ-L2CiuSX4iTfevpySjfsJmcokM8SqaFN1v3gigDWH02fmlrFbd6mmEfbN)) for unsupervised manifold learning.\n",
        "\n",
        "We will compare applying it on either the waveform and scattering transform of the signals, on the simple dataset (one f0) and the complex dataset (sample f0). "
      ],
      "metadata": {
        "id": "S7YuNDvWGhxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_manifold(Xmat, n_components=2, n_neighbors=50, n_r=50, n_alpha=50, N=2**10):\n",
        "\n",
        "    raw_isomap = Isomap(n_neighbors=n_neighbors, n_components=n_components)\n",
        "    raw_iso = raw_isomap.fit_transform(Xmat)\n",
        "    raw_isoReshape = raw_iso.reshape((n_r, n_alpha, n_components))\n",
        "    \n",
        "    return raw_isoReshape\n"
      ],
      "metadata": {
        "id": "JHSFt971GoVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_components=2\n",
        "n_neighbors=50\n",
        "Xmat_simple = X_simple.reshape((n_r*n_alpha, N))\n",
        "\n",
        "raw_isoReshape = make_manifold(Xmat_simple, n_components, n_neighbors, n_r, n_alpha, N)"
      ],
      "metadata": {
        "id": "og91bGclGqsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to visualize the manifold, for the simple dataset. This manifold is learn directly on the waveform, without transforming the generated audio signal. "
      ],
      "metadata": {
        "id": "F_cIiKh1G0Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_tiled = np.tile(alpha_range, (n_r, 1));\n",
        "r_tiled = np.tile(r_range, (n_alpha, 1)).T;\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=True)\n",
        "axs[0].scatter(\n",
        "    np.ravel(raw_isoReshape[:, :, 0]),\n",
        "    np.ravel(raw_isoReshape[:, :, 1]),\n",
        "    c = np.ravel(r_tiled), cmap='coolwarm');\n",
        "axs[1].scatter(\n",
        "    np.ravel(raw_isoReshape[:, :, 0]),\n",
        "    np.ravel(raw_isoReshape[:, :, 1]),\n",
        "    c = np.ravel(alpha_tiled), cmap='coolwarm');"
      ],
      "metadata": {
        "id": "3fV72q-bG0s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how things go with the more complex dataset :"
      ],
      "metadata": {
        "id": "IwkUgq7BG63q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xmat = X.reshape((n_r*n_alpha, N))\n",
        "\n",
        "\n",
        "raw_isoReshape = make_manifold(Xmat,  n_components, n_neighbors, n_r, n_alpha, N)\n",
        "\n",
        "\n",
        "alpha_tiled = np.tile(alpha_range, (n_r, 1));\n",
        "r_tiled = np.tile(r_range, (n_alpha, 1)).T;\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=True)\n",
        "axs[0].scatter(\n",
        "    np.ravel(raw_isoReshape[:, :, 0]),\n",
        "    np.ravel(raw_isoReshape[:, :, 1]),\n",
        "    c = np.ravel(r_tiled), cmap='coolwarm');\n",
        "axs[1].scatter(\n",
        "    np.ravel(raw_isoReshape[:, :, 0]),\n",
        "    np.ravel(raw_isoReshape[:, :, 1]),\n",
        "    c = np.ravel(alpha_tiled), cmap='coolwarm');"
      ],
      "metadata": {
        "id": "EZlxSRrwG8tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What differences can you see between the two manifolds ?\n",
        "\n",
        "\n",
        "Let's try it with the scattering transform."
      ],
      "metadata": {
        "id": "t_sIxyW_HClN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_scattering(X, n_r=50, n_alpha=50, N=2**10):\n",
        "\n",
        "    Xmat = X.reshape((n_r*n_alpha, N))\n",
        "\n",
        "    scattering = kymatio.Scattering1D(J=int(np.log2(N)), Q=1, shape=(N,))\n",
        "    Xmat_torch = torch.from_numpy(Xmat).float()\n",
        "    Smat = np.maximum(0, scattering(Xmat_torch).numpy()[:, :, 0])\n",
        "    return Smat"
      ],
      "metadata": {
        "id": "-YOPoinlHFIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Smat = make_scattering(X_simple, n_r, n_alpha)"
      ],
      "metadata": {
        "id": "jKUzttQSHOt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now, learn a manifold for this matrix"
      ],
      "metadata": {
        "id": "rZHMME9fHSsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_components = 3\n",
        "n_neighbors = 100\n",
        "\n",
        "manifold_scattering = make_manifold(Smat, n_components, n_neighbors,  n_r, n_alpha, N)\n",
        "\n",
        "alpha_tiled = np.tile(alpha_range, (n_r, 1));\n",
        "r_tiled = np.tile(r_range, (n_alpha, 1)).T;\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharex=False, sharey=True)\n",
        "axs = axs.flatten()\n",
        "\n",
        "axs[0].scatter(\n",
        "    np.ravel(manifold_scattering[:, :, 0]),\n",
        "    np.ravel(manifold_scattering[:, :, 1]),\n",
        "    c = np.ravel(r_tiled), cmap='coolwarm');\n",
        "axs[1].scatter(\n",
        "    np.ravel(manifold_scattering[:, :, 0]),\n",
        "    np.ravel(manifold_scattering[:, :, 1]),\n",
        "    c = np.ravel(alpha_tiled), cmap='coolwarm');\n"
      ],
      "metadata": {
        "id": "vENtAPsjHVLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you see a difference between the manifold learn on waveform and on scattering trasnform for the simple dataset ?\n",
        "\n",
        "Now, we do the same but with the complex dataset."
      ],
      "metadata": {
        "id": "5CdkPVewHcsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Smat = make_scattering(X, n_r, n_alpha)\n",
        "\n",
        "n_components = 3\n",
        "n_neighbors = 100\n",
        "\n",
        "manifold_scattering = make_manifold(Smat, n_components, n_neighbors,   n_r, n_alpha, N)"
      ],
      "metadata": {
        "id": "IT8pJefxHj3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_tiled = np.tile(alpha_range, (n_r, 1));\n",
        "r_tiled = np.tile(r_range, (n_alpha, 1)).T;\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharex=False, sharey=True)\n",
        "axs = axs.flatten()\n",
        "\n",
        "axs[0].scatter(\n",
        "    np.ravel(manifold_scattering[:, :, 0]),\n",
        "    np.ravel(manifold_scattering[:, :, 1]),\n",
        "    c = np.ravel(r_tiled), cmap='coolwarm');\n",
        "axs[1].scatter(\n",
        "    np.ravel(manifold_scattering[:, :, 0]),\n",
        "    np.ravel(manifold_scattering[:, :, 1]),\n",
        "    c = np.ravel(alpha_tiled), cmap='coolwarm');\n",
        "axs[2].scatter(\n",
        "    np.ravel(manifold_scattering[:, :, 0]),\n",
        "    np.ravel(manifold_scattering[:, :, 1]),\n",
        "    c = np.ravel(frequencies), cmap='coolwarm');"
      ],
      "metadata": {
        "id": "afaqmzlzHlfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What differences between the two manifold for the complex dataset do you see ? \n",
        "Can you retrieve the parameters of our signals ?\n",
        "\n",
        "\n",
        "We can also vizualise the manifold in 3D :\n"
      ],
      "metadata": {
        "id": "JMM9wNIbHqZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(\n",
        "    manifold_scattering[:, :, 0],\n",
        "    manifold_scattering[:, :, 1],\n",
        "    manifold_scattering[:, :, 2],\n",
        "    c=np.ravel(r_tiled),\n",
        "    s=6.0,\n",
        "    alpha=0.5, cmap='coolwarm')\n",
        "\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('')\n",
        "ax.set_zlabel('')\n",
        "plt.gca().set_xticklabels([])\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.gca().set_zticklabels([])\n",
        "plt.gca().grid(color='g')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(\n",
        "    manifold_scattering[:, :, 0],\n",
        "    manifold_scattering[:, :, 1],\n",
        "    manifold_scattering[:, :, 2],\n",
        "    c=np.ravel(alpha_tiled),\n",
        "    s=20.0,\n",
        "    alpha=0.5, cmap='coolwarm')\n",
        "\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('')\n",
        "ax.set_zlabel('')\n",
        "plt.gca().set_xticklabels([])\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.gca().set_zticklabels([])\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(\n",
        "    manifold_scattering[:, :, 0],\n",
        "    manifold_scattering[:, :, 1],\n",
        "    manifold_scattering[:, :, 2],\n",
        "    c=-np.ravel(frequencies),\n",
        "    s=6.0,\n",
        "    alpha=0.5, cmap='coolwarm')\n",
        "\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('')\n",
        "ax.set_zlabel('')\n",
        "plt.gca().set_xticklabels([])\n",
        "plt.gca().set_yticklabels([])\n",
        "plt.gca().set_zticklabels([])\n"
      ],
      "metadata": {
        "id": "1jtjtaV3HzGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}